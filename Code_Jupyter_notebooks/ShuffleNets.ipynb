{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ShuffleNets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c64VHtfePCfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a8dcd5e-e5ad-4350-8fd0-013c927e28d0"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.models import Model\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.layers import Activation, Add, Concatenate, GlobalAveragePooling2D,GlobalMaxPooling2D, Input, Dense\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, Lambda\n",
        "#from keras_applications.mobilenet import DepthwiseConv2D\n",
        "from keras.layers import DepthwiseConv2D\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def ShuffleNet(include_top=True, input_tensor=None, scale_factor=1.0, pooling='max',\n",
        "               input_shape=(224,224,3), groups=1, load_model=None, num_shuffle_units=[3, 7, 3],\n",
        "               bottleneck_ratio=0.25, classes=1000):\n",
        "    \"\"\"\n",
        "    ShuffleNet implementation for Keras 2\n",
        "\n",
        "    ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices\n",
        "    Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, Jian Sun\n",
        "    https://arxiv.org/pdf/1707.01083.pdf\n",
        "\n",
        "    Note that only TensorFlow is supported for now, therefore it only works\n",
        "    with the data format `image_data_format='channels_last'` in your Keras\n",
        "    config at `~/.keras/keras.json`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    include_top: bool(True)\n",
        "         whether to include the fully-connected layer at the top of the network.\n",
        "    input_tensor:\n",
        "        optional Keras tensor (i.e. output of `layers.Input()`) to use as image input for the model.\n",
        "    scale_factor:\n",
        "        scales the number of output channels\n",
        "    input_shape:\n",
        "    pooling:\n",
        "        Optional pooling mode for feature extraction\n",
        "        when `include_top` is `False`.\n",
        "        - `None` means that the output of the model\n",
        "            will be the 4D tensor output of the\n",
        "            last convolutional layer.\n",
        "        - `avg` means that global average pooling\n",
        "            will be applied to the output of the\n",
        "            last convolutional layer, and thus\n",
        "            the output of the model will be a\n",
        "            2D tensor.\n",
        "        - `max` means that global max pooling will\n",
        "            be applied.\n",
        "    groups: int\n",
        "        number of groups per channel\n",
        "    num_shuffle_units: list([3,7,3])\n",
        "        number of stages (list length) and the number of shufflenet units in a\n",
        "        stage beginning with stage 2 because stage 1 is fixed\n",
        "\n",
        "        e.g. idx 0 contains 3 + 1 (first shuffle unit in each stage differs) shufflenet units for stage 2\n",
        "        idx 1 contains 7 + 1 Shufflenet Units for stage 3 and\n",
        "        idx 2 contains 3 + 1 Shufflenet Units\n",
        "    bottleneck_ratio:\n",
        "        bottleneck ratio implies the ratio of bottleneck channels to output channels.\n",
        "        For example, bottleneck ratio = 1 : 4 means the output feature map is 4 times\n",
        "        the width of the bottleneck feature map.\n",
        "    classes: int(1000)\n",
        "        number of classes to predict\n",
        "    Returns\n",
        "    -------\n",
        "        A Keras model instance\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    - [ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices]\n",
        "      (http://www.arxiv.org/pdf/1707.01083.pdf)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if K.backend() != 'tensorflow':\n",
        "        raise RuntimeError('Only TensorFlow backend is currently supported, '\n",
        "                           'as other backends do not support ')\n",
        "\n",
        "    name = \"ShuffleNet_%.2gX_g%d_br_%.2g_%s\" % (scale_factor, groups, bottleneck_ratio, \"\".join([str(x) for x in num_shuffle_units]))\n",
        "\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=28,\n",
        "                                      require_flatten=include_top,\n",
        "                                      data_format=K.image_data_format())\n",
        "\n",
        "    out_dim_stage_two = {1: 144, 2: 200, 3: 240, 4: 272, 8: 384}\n",
        "    if groups not in out_dim_stage_two:\n",
        "        raise ValueError(\"Invalid number of groups.\")\n",
        "\n",
        "    if pooling not in ['max','avg']:\n",
        "        raise ValueError(\"Invalid value for pooling.\")\n",
        "\n",
        "    if not (float(scale_factor) * 4).is_integer():\n",
        "        raise ValueError(\"Invalid value for scale_factor. Should be x over 4.\")\n",
        "\n",
        "    exp = np.insert(np.arange(0, len(num_shuffle_units), dtype=np.float32), 0, 0)\n",
        "    out_channels_in_stage = 2 ** exp\n",
        "    out_channels_in_stage *= out_dim_stage_two[groups]  # calculate output channels for each stage\n",
        "    out_channels_in_stage[0] = 24  # first stage has always 24 output channels\n",
        "    out_channels_in_stage *= scale_factor\n",
        "    out_channels_in_stage = out_channels_in_stage.astype(int)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    # create shufflenet architecture\n",
        "    x = Conv2D(filters=out_channels_in_stage[0], kernel_size=(3, 3), padding='same',\n",
        "               use_bias=False, strides=(2, 2), activation=\"relu\", name=\"conv1\")(img_input)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same', name=\"maxpool1\")(x)\n",
        "\n",
        "    # create stages containing shufflenet units beginning at stage 2\n",
        "    for stage in range(0, len(num_shuffle_units)):\n",
        "        repeat = num_shuffle_units[stage]\n",
        "        x = _block(x, out_channels_in_stage, repeat=repeat,\n",
        "                   bottleneck_ratio=bottleneck_ratio,\n",
        "                   groups=groups, stage=stage + 2)\n",
        "\n",
        "    if pooling == 'avg':\n",
        "        x = GlobalAveragePooling2D(name=\"global_pool\")(x)\n",
        "    elif pooling == 'max':\n",
        "        x = GlobalMaxPooling2D(name=\"global_pool\")(x)\n",
        "\n",
        "    if include_top:\n",
        "        x = Dense(units=classes, name=\"fc\")(x)\n",
        "        x = Activation('softmax', name='softmax')(x)\n",
        "\n",
        "\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=x, name=name)\n",
        "\n",
        "    if load_model is not None:\n",
        "        model.load_weights('', by_name=True)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def _block(x, channel_map, bottleneck_ratio, repeat=1, groups=1, stage=1):\n",
        "    \"\"\"\n",
        "    creates a bottleneck block containing `repeat + 1` shuffle units\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x:\n",
        "        Input tensor of with `channels_last` data format\n",
        "    channel_map: list\n",
        "        list containing the number of output channels for a stage\n",
        "    repeat: int(1)\n",
        "        number of repetitions for a shuffle unit with stride 1\n",
        "    groups: int(1)\n",
        "        number of groups per channel\n",
        "    bottleneck_ratio: float\n",
        "        bottleneck ratio implies the ratio of bottleneck channels to output channels.\n",
        "        For example, bottleneck ratio = 1 : 4 means the output feature map is 4 times\n",
        "        the width of the bottleneck feature map.\n",
        "    stage: int(1)\n",
        "        stage number\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    \"\"\"\n",
        "    x = _shuffle_unit(x, in_channels=channel_map[stage - 2],\n",
        "                      out_channels=channel_map[stage - 1], strides=2,\n",
        "                      groups=groups, bottleneck_ratio=bottleneck_ratio,\n",
        "                      stage=stage, block=1)\n",
        "\n",
        "    for i in range(1, repeat + 1):\n",
        "        x = _shuffle_unit(x, in_channels=channel_map[stage - 1],\n",
        "                          out_channels=channel_map[stage - 1], strides=1,\n",
        "                          groups=groups, bottleneck_ratio=bottleneck_ratio,\n",
        "                          stage=stage, block=(i + 1))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def _shuffle_unit(inputs, in_channels, out_channels, groups, bottleneck_ratio, strides=2, stage=1, block=1):\n",
        "    \"\"\"\n",
        "    creates a shuffleunit\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    inputs:\n",
        "        Input tensor of with `channels_last` data format\n",
        "    in_channels:\n",
        "        number of input channels\n",
        "    out_channels:\n",
        "        number of output channels\n",
        "    strides:\n",
        "        An integer or tuple/list of 2 integers,\n",
        "        specifying the strides of the convolution along the width and height.\n",
        "    groups: int(1)\n",
        "        number of groups per channel\n",
        "    bottleneck_ratio: float\n",
        "        bottleneck ratio implies the ratio of bottleneck channels to output channels.\n",
        "        For example, bottleneck ratio = 1 : 4 means the output feature map is 4 times\n",
        "        the width of the bottleneck feature map.\n",
        "    stage: int(1)\n",
        "        stage number\n",
        "    block: int(1)\n",
        "        block number\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    \"\"\"\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = -1\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    prefix = 'stage%d/block%d' % (stage, block)\n",
        "\n",
        "    #if strides >= 2:\n",
        "        #out_channels -= in_channels\n",
        "\n",
        "    # default: 1/4 of the output channel of a ShuffleNet Unit\n",
        "    bottleneck_channels = int(out_channels * bottleneck_ratio)\n",
        "    groups = (1 if stage == 2 and block == 1 else groups)\n",
        "\n",
        "    x = _group_conv(inputs, in_channels, out_channels=bottleneck_channels,\n",
        "                    groups=(1 if stage == 2 and block == 1 else groups),\n",
        "                    name='%s/1x1_gconv_1' % prefix)\n",
        "    x = BatchNormalization(axis=bn_axis, name='%s/bn_gconv_1' % prefix)(x)\n",
        "    x = Activation('relu', name='%s/relu_gconv_1' % prefix)(x)\n",
        "\n",
        "    x = Lambda(channel_shuffle, arguments={'groups': groups}, name='%s/channel_shuffle' % prefix)(x)\n",
        "    x = DepthwiseConv2D(kernel_size=(3, 3), padding=\"same\", use_bias=False,\n",
        "                        strides=strides, name='%s/1x1_dwconv_1' % prefix)(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name='%s/bn_dwconv_1' % prefix)(x)\n",
        "\n",
        "    x = _group_conv(x, bottleneck_channels, out_channels=out_channels if strides == 1 else out_channels - in_channels,\n",
        "                    groups=groups, name='%s/1x1_gconv_2' % prefix)\n",
        "    x = BatchNormalization(axis=bn_axis, name='%s/bn_gconv_2' % prefix)(x)\n",
        "\n",
        "    if strides < 2:\n",
        "        ret = Add(name='%s/add' % prefix)([x, inputs])\n",
        "    else:\n",
        "        avg = AveragePooling2D(pool_size=3, strides=2, padding='same', name='%s/avg_pool' % prefix)(inputs)\n",
        "        ret = Concatenate(bn_axis, name='%s/concat' % prefix)([x, avg])\n",
        "\n",
        "    ret = Activation('relu', name='%s/relu_out' % prefix)(ret)\n",
        "\n",
        "    return ret\n",
        "\n",
        "\n",
        "def _group_conv(x, in_channels, out_channels, groups, kernel=1, stride=1, name=''):\n",
        "    \"\"\"\n",
        "    grouped convolution\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x:\n",
        "        Input tensor of with `channels_last` data format\n",
        "    in_channels:\n",
        "        number of input channels\n",
        "    out_channels:\n",
        "        number of output channels\n",
        "    groups:\n",
        "        number of groups per channel\n",
        "    kernel: int(1)\n",
        "        An integer or tuple/list of 2 integers, specifying the\n",
        "        width and height of the 2D convolution window.\n",
        "        Can be a single integer to specify the same value for\n",
        "        all spatial dimensions.\n",
        "    stride: int(1)\n",
        "        An integer or tuple/list of 2 integers,\n",
        "        specifying the strides of the convolution along the width and height.\n",
        "        Can be a single integer to specify the same value for all spatial dimensions.\n",
        "    name: str\n",
        "        A string to specifies the layer name\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    \"\"\"\n",
        "    if groups == 1:\n",
        "        return Conv2D(filters=out_channels, kernel_size=kernel, padding='same',\n",
        "                      use_bias=False, strides=stride, name=name)(x)\n",
        "\n",
        "    # number of intput channels per group\n",
        "    ig = in_channels // groups\n",
        "    group_list = []\n",
        "\n",
        "    assert out_channels % groups == 0\n",
        "\n",
        "    for i in range(groups):\n",
        "        offset = i * ig\n",
        "        group = Lambda(lambda z: z[:, :, :, offset: offset + ig], name='%s/g%d_slice' % (name, i))(x)\n",
        "        group_list.append(Conv2D(int(0.5 + out_channels / groups), kernel_size=kernel, strides=stride,\n",
        "                                 use_bias=False, padding='same', name='%s_/g%d' % (name, i))(group))\n",
        "    return Concatenate(name='%s/concat' % name)(group_list)\n",
        "\n",
        "\n",
        "def channel_shuffle(x, groups):\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x:\n",
        "        Input tensor of with `channels_last` data format\n",
        "    groups: int\n",
        "        number of groups per channel\n",
        "\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        channel shuffled output tensor\n",
        "\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    Example for a 1D Array with 3 groups\n",
        "\n",
        "    >>> d = np.array([0,1,2,3,4,5,6,7,8])\n",
        "    >>> x = np.reshape(d, (3,3))\n",
        "    >>> x = np.transpose(x, [1,0])\n",
        "    >>> x = np.reshape(x, (9,))\n",
        "    '[0 1 2 3 4 5 6 7 8] --> [0 3 6 1 4 7 2 5 8]'\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    height, width, in_channels = x.shape.as_list()[1:]\n",
        "    channels_per_group = in_channels // groups\n",
        "\n",
        "    x = K.reshape(x, [-1, height, width, groups, channels_per_group])\n",
        "    x = K.permute_dimensions(x, (0, 1, 2, 4, 3))  # transpose\n",
        "    x = K.reshape(x, [-1, height, width, in_channels])\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9qFDJRpRHBq",
        "colab_type": "code",
        "outputId": "b857a32c-b3ef-469b-f749-76b2f5955943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/My\\ Drive\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy\n",
        "\n",
        "#from keras_efficientnets import EfficientNetB0\n",
        "#from keras_squeezenet import SqueezeNet\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3caF4_6RNg0",
        "colab_type": "code",
        "outputId": "41f98d20-cddc-427f-e21f-a030b4b8ae6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "train_datagen= ImageDataGenerator()\n",
        "valid_datagen= ImageDataGenerator()\n",
        "test_datagen= ImageDataGenerator()\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\n",
        "    directory='PATH/TO/TRAIN/DATASET',\n",
        "\n",
        "    target_size=(224, 224),\n",
        "\n",
        "    color_mode=\"rgb\",\n",
        "\n",
        "    batch_size=32,\n",
        "\n",
        "    class_mode=\"categorical\",\n",
        "\n",
        "    shuffle=True,\n",
        "\n",
        "    seed=42)\n",
        "\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "\n",
        "    directory='PATH/TO/VALID/DATASET',\n",
        "\n",
        "    target_size=(224, 224),\n",
        "\n",
        "    color_mode=\"rgb\",\n",
        "\n",
        "    batch_size=32,\n",
        "\n",
        "    class_mode=\"categorical\",\n",
        "\n",
        "    shuffle=True,\n",
        "\n",
        "    seed=42)\n",
        "\n",
        "test_generator= test_datagen.flow_from_directory(\n",
        "\n",
        "   directory='PATH/TO/VALID/DATASET',\n",
        "\n",
        "   target_size=(224,224),color_mode=\"rgb\",\n",
        "\n",
        "   class_mode=\"categorical\",shuffle=False,seed=42)\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "\n",
        "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4033 images belonging to 7 classes.\n",
            "Found 1225 images belonging to 7 classes.\n",
            "Found 221 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUluRwg75Ld5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = ShuffleNet(include_top=False, input_tensor=None,\n",
        "                        scale_factor=1.0, pooling='avg',input_shape=(224,224,3),\n",
        "                        groups=1, load_model=None,\n",
        "                        num_shuffle_units=[3, 7, 3],bottleneck_ratio=0.25,\n",
        "                        classes=1000)\n",
        "x = base_model.output\n",
        "x = Dense(units=7, name=\"fc\")(x)\n",
        "x = Activation('softmax', name='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEvXeoXd5lAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6qqglIK5twx",
        "colab_type": "code",
        "outputId": "4bc0c017-e541-4514-bbe0-77880c127026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 24) 648         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "maxpool1 (MaxPooling2D)         (None, 56, 56, 24)   0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block1/1x1_gconv_1 (Conv (None, 56, 56, 36)   864         maxpool1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block1/bn_gconv_1 (Batch (None, 56, 56, 36)   144         stage2/block1/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block1/relu_gconv_1 (Act (None, 56, 56, 36)   0           stage2/block1/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block1/channel_shuffle ( (None, 56, 56, 36)   0           stage2/block1/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block1/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block1/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage2/block1/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block1/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block1/1x1_gconv_2 (Conv (None, 28, 28, 120)  4320        stage2/block1/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block1/bn_gconv_2 (Batch (None, 28, 28, 120)  480         stage2/block1/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block1/avg_pool (Average (None, 28, 28, 24)   0           maxpool1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block1/concat (Concatena (None, 28, 28, 144)  0           stage2/block1/bn_gconv_2[0][0]   \n",
            "                                                                 stage2/block1/avg_pool[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block1/relu_out (Activat (None, 28, 28, 144)  0           stage2/block1/concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block2/1x1_gconv_1 (Conv (None, 28, 28, 36)   5184        stage2/block1/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block2/bn_gconv_1 (Batch (None, 28, 28, 36)   144         stage2/block2/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block2/relu_gconv_1 (Act (None, 28, 28, 36)   0           stage2/block2/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block2/channel_shuffle ( (None, 28, 28, 36)   0           stage2/block2/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block2/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block2/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage2/block2/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block2/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block2/1x1_gconv_2 (Conv (None, 28, 28, 144)  5184        stage2/block2/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block2/bn_gconv_2 (Batch (None, 28, 28, 144)  576         stage2/block2/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block2/add (Add)         (None, 28, 28, 144)  0           stage2/block2/bn_gconv_2[0][0]   \n",
            "                                                                 stage2/block1/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block2/relu_out (Activat (None, 28, 28, 144)  0           stage2/block2/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block3/1x1_gconv_1 (Conv (None, 28, 28, 36)   5184        stage2/block2/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block3/bn_gconv_1 (Batch (None, 28, 28, 36)   144         stage2/block3/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block3/relu_gconv_1 (Act (None, 28, 28, 36)   0           stage2/block3/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block3/channel_shuffle ( (None, 28, 28, 36)   0           stage2/block3/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block3/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block3/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage2/block3/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block3/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block3/1x1_gconv_2 (Conv (None, 28, 28, 144)  5184        stage2/block3/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block3/bn_gconv_2 (Batch (None, 28, 28, 144)  576         stage2/block3/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block3/add (Add)         (None, 28, 28, 144)  0           stage2/block3/bn_gconv_2[0][0]   \n",
            "                                                                 stage2/block2/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block3/relu_out (Activat (None, 28, 28, 144)  0           stage2/block3/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block4/1x1_gconv_1 (Conv (None, 28, 28, 36)   5184        stage2/block3/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block4/bn_gconv_1 (Batch (None, 28, 28, 36)   144         stage2/block4/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block4/relu_gconv_1 (Act (None, 28, 28, 36)   0           stage2/block4/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block4/channel_shuffle ( (None, 28, 28, 36)   0           stage2/block4/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block4/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block4/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage2/block4/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block4/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block4/1x1_gconv_2 (Conv (None, 28, 28, 144)  5184        stage2/block4/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block4/bn_gconv_2 (Batch (None, 28, 28, 144)  576         stage2/block4/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block4/add (Add)         (None, 28, 28, 144)  0           stage2/block4/bn_gconv_2[0][0]   \n",
            "                                                                 stage2/block3/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage2/block4/relu_out (Activat (None, 28, 28, 144)  0           stage2/block4/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block1/1x1_gconv_1 (Conv (None, 28, 28, 72)   10368       stage2/block4/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block1/bn_gconv_1 (Batch (None, 28, 28, 72)   288         stage3/block1/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block1/relu_gconv_1 (Act (None, 28, 28, 72)   0           stage3/block1/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block1/channel_shuffle ( (None, 28, 28, 72)   0           stage3/block1/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block1/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block1/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage3/block1/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block1/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block1/1x1_gconv_2 (Conv (None, 14, 14, 144)  10368       stage3/block1/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block1/bn_gconv_2 (Batch (None, 14, 14, 144)  576         stage3/block1/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block1/avg_pool (Average (None, 14, 14, 144)  0           stage2/block4/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block1/concat (Concatena (None, 14, 14, 288)  0           stage3/block1/bn_gconv_2[0][0]   \n",
            "                                                                 stage3/block1/avg_pool[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block1/relu_out (Activat (None, 14, 14, 288)  0           stage3/block1/concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block2/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block1/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block2/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block2/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block2/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block2/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block2/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block2/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block2/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block2/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage3/block2/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block2/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block2/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block2/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block2/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block2/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block2/add (Add)         (None, 14, 14, 288)  0           stage3/block2/bn_gconv_2[0][0]   \n",
            "                                                                 stage3/block1/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block2/relu_out (Activat (None, 14, 14, 288)  0           stage3/block2/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block3/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block2/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block3/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block3/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block3/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block3/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block3/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block3/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block3/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block3/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage3/block3/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block3/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block3/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block3/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block3/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block3/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block3/add (Add)         (None, 14, 14, 288)  0           stage3/block3/bn_gconv_2[0][0]   \n",
            "                                                                 stage3/block2/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block3/relu_out (Activat (None, 14, 14, 288)  0           stage3/block3/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block4/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block3/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block4/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block4/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block4/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block4/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block4/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block4/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block4/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block4/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage3/block4/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block4/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block4/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block4/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block4/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block4/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block4/add (Add)         (None, 14, 14, 288)  0           stage3/block4/bn_gconv_2[0][0]   \n",
            "                                                                 stage3/block3/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block4/relu_out (Activat (None, 14, 14, 288)  0           stage3/block4/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block5/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block4/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block5/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block5/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block5/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block5/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block5/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block5/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block5/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block5/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage3/block5/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block5/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block5/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block5/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block5/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block5/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block5/add (Add)         (None, 14, 14, 288)  0           stage3/block5/bn_gconv_2[0][0]   \n",
            "                                                                 stage3/block4/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block5/relu_out (Activat (None, 14, 14, 288)  0           stage3/block5/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block6/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block5/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block6/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block6/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block6/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block6/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block6/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block6/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block6/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block6/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage3/block6/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block6/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block6/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block6/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block6/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block6/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block6/add (Add)         (None, 14, 14, 288)  0           stage3/block6/bn_gconv_2[0][0]   \n",
            "                                                                 stage3/block5/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block6/relu_out (Activat (None, 14, 14, 288)  0           stage3/block6/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block7/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block6/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block7/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block7/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block7/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block7/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block7/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block7/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block7/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block7/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage3/block7/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block7/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block7/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block7/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block7/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block7/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block7/add (Add)         (None, 14, 14, 288)  0           stage3/block7/bn_gconv_2[0][0]   \n",
            "                                                                 stage3/block6/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block7/relu_out (Activat (None, 14, 14, 288)  0           stage3/block7/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block8/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block7/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block8/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block8/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block8/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block8/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block8/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block8/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block8/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block8/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage3/block8/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block8/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block8/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block8/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block8/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block8/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block8/add (Add)         (None, 14, 14, 288)  0           stage3/block8/bn_gconv_2[0][0]   \n",
            "                                                                 stage3/block7/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage3/block8/relu_out (Activat (None, 14, 14, 288)  0           stage3/block8/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block1/1x1_gconv_1 (Conv (None, 14, 14, 144)  41472       stage3/block8/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block1/bn_gconv_1 (Batch (None, 14, 14, 144)  576         stage4/block1/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block1/relu_gconv_1 (Act (None, 14, 14, 144)  0           stage4/block1/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block1/channel_shuffle ( (None, 14, 14, 144)  0           stage4/block1/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block1/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block1/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage4/block1/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block1/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block1/1x1_gconv_2 (Conv (None, 7, 7, 288)    41472       stage4/block1/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block1/bn_gconv_2 (Batch (None, 7, 7, 288)    1152        stage4/block1/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block1/avg_pool (Average (None, 7, 7, 288)    0           stage3/block8/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block1/concat (Concatena (None, 7, 7, 576)    0           stage4/block1/bn_gconv_2[0][0]   \n",
            "                                                                 stage4/block1/avg_pool[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block1/relu_out (Activat (None, 7, 7, 576)    0           stage4/block1/concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block2/1x1_gconv_1 (Conv (None, 7, 7, 144)    82944       stage4/block1/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block2/bn_gconv_1 (Batch (None, 7, 7, 144)    576         stage4/block2/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block2/relu_gconv_1 (Act (None, 7, 7, 144)    0           stage4/block2/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block2/channel_shuffle ( (None, 7, 7, 144)    0           stage4/block2/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block2/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block2/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage4/block2/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block2/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block2/1x1_gconv_2 (Conv (None, 7, 7, 576)    82944       stage4/block2/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block2/bn_gconv_2 (Batch (None, 7, 7, 576)    2304        stage4/block2/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block2/add (Add)         (None, 7, 7, 576)    0           stage4/block2/bn_gconv_2[0][0]   \n",
            "                                                                 stage4/block1/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block2/relu_out (Activat (None, 7, 7, 576)    0           stage4/block2/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block3/1x1_gconv_1 (Conv (None, 7, 7, 144)    82944       stage4/block2/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block3/bn_gconv_1 (Batch (None, 7, 7, 144)    576         stage4/block3/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block3/relu_gconv_1 (Act (None, 7, 7, 144)    0           stage4/block3/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block3/channel_shuffle ( (None, 7, 7, 144)    0           stage4/block3/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block3/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block3/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage4/block3/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block3/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block3/1x1_gconv_2 (Conv (None, 7, 7, 576)    82944       stage4/block3/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block3/bn_gconv_2 (Batch (None, 7, 7, 576)    2304        stage4/block3/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block3/add (Add)         (None, 7, 7, 576)    0           stage4/block3/bn_gconv_2[0][0]   \n",
            "                                                                 stage4/block2/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block3/relu_out (Activat (None, 7, 7, 576)    0           stage4/block3/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block4/1x1_gconv_1 (Conv (None, 7, 7, 144)    82944       stage4/block3/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block4/bn_gconv_1 (Batch (None, 7, 7, 144)    576         stage4/block4/1x1_gconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block4/relu_gconv_1 (Act (None, 7, 7, 144)    0           stage4/block4/bn_gconv_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block4/channel_shuffle ( (None, 7, 7, 144)    0           stage4/block4/relu_gconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block4/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block4/channel_shuffle[0][\n",
            "__________________________________________________________________________________________________\n",
            "stage4/block4/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block4/1x1_dwconv_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block4/1x1_gconv_2 (Conv (None, 7, 7, 576)    82944       stage4/block4/bn_dwconv_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block4/bn_gconv_2 (Batch (None, 7, 7, 576)    2304        stage4/block4/1x1_gconv_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block4/add (Add)         (None, 7, 7, 576)    0           stage4/block4/bn_gconv_2[0][0]   \n",
            "                                                                 stage4/block3/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "stage4/block4/relu_out (Activat (None, 7, 7, 576)    0           stage4/block4/add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_pool (GlobalAveragePooli (None, 576)          0           stage4/block4/relu_out[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "fc (Dense)                      (None, 7)            4039        global_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Activation)            (None, 7)            0           fc[0][0]                         \n",
            "==================================================================================================\n",
            "Total params: 973,567\n",
            "Trainable params: 958,927\n",
            "Non-trainable params: 14,640\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDpG80Pv5wSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(generator=train_generator,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}