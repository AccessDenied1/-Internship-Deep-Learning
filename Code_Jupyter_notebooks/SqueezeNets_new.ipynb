{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SqueezeNets_new.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSRjOmUWFHzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout\n",
        "import warnings\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.utils import get_file\n",
        "from keras.utils import layer_utils\n",
        "\n",
        "\n",
        "sq1x1 = \"squeeze1x1\"\n",
        "exp1x1 = \"expand1x1\"\n",
        "exp3x3 = \"expand3x3\"\n",
        "relu = \"relu_\"\n",
        "\n",
        "WEIGHTS_PATH = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels.h5\"\n",
        "WEIGHTS_PATH_NO_TOP = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "\n",
        "# Modular function for Fire Node\n",
        "\n",
        "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
        "    s_id = 'fire' + str(fire_id) + '/'\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = 3\n",
        "    \n",
        "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
        "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
        "\n",
        "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
        "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
        "\n",
        "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
        "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
        "\n",
        "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
        "    return x\n",
        "\n",
        "\n",
        "# Original SqueezeNet from paper.\n",
        "\n",
        "def SqueezeNet(include_top=True, weights='imagenet',\n",
        "               input_tensor=None, input_shape=None,\n",
        "               pooling=None,\n",
        "               classes=1000):\n",
        "    \"\"\"Instantiates the SqueezeNet architecture.\n",
        "    \"\"\"\n",
        "        \n",
        "    if weights not in {'imagenet', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `imagenet` '\n",
        "                         '(pre-training on ImageNet).')\n",
        "\n",
        "    if weights == 'imagenet' and classes != 1000:\n",
        "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=227,\n",
        "                                      min_size=48,\n",
        "                                      data_format=K.image_data_format(),\n",
        "                                      require_flatten=include_top)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "\n",
        "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
        "    x = Activation('relu', name='relu_conv1')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
        "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
        "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
        "\n",
        "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
        "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
        "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
        "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
        "    \n",
        "    if include_top:\n",
        "        # It's not obvious where to cut the network... \n",
        "        # Could do the 8th or 9th layer... some work recommends cutting earlier layers.\n",
        "    \n",
        "        x = Dropout(0.5, name='drop9')(x)\n",
        "\n",
        "        x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
        "        x = Activation('relu', name='relu_conv10')(x)\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Activation('softmax', name='loss')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling=='max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "        elif pooling==None:\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError(\"Unknown argument for 'pooling'=\" + pooling)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "\n",
        "    model = Model(inputs, x, name='squeezenet')\n",
        "\n",
        "    # load weights\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                                    WEIGHTS_PATH,\n",
        "                                    cache_subdir='models')\n",
        "        else:\n",
        "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                                    WEIGHTS_PATH_NO_TOP,\n",
        "                                    cache_subdir='models')\n",
        "            \n",
        "        model.load_weights(weights_path)\n",
        "        if K.backend() == 'theano':\n",
        "            layer_utils.convert_all_kernels_in_model(model)\n",
        "\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "\n",
        "            if K.backend() == 'tensorflow':\n",
        "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                              'are using the Theano '\n",
        "                              'image data format convention '\n",
        "                              '(`image_data_format=\"channels_first\"`). '\n",
        "                              'For best performance, set '\n",
        "                              '`image_data_format=\"channels_last\"` in '\n",
        "                              'your Keras config '\n",
        "                              'at ~/.keras/keras.json.')\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyXz1cEvQwjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_eUgWI4FnPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import os\n",
        "import numpy\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlIcE8SNFskB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen= ImageDataGenerator()\n",
        "valid_datagen= ImageDataGenerator()\n",
        "test_datagen= ImageDataGenerator()\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\n",
        "    directory='PATH/TO/TRAIN/DATASET',\n",
        "\n",
        "    target_size=(224, 224),\n",
        "\n",
        "    color_mode=\"rgb\",\n",
        "\n",
        "    batch_size=32,\n",
        "\n",
        "    class_mode=\"categorical\",\n",
        "\n",
        "    shuffle=True,\n",
        "\n",
        "    seed=42)\n",
        "\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "\n",
        "    directory='PATH/TO/VALID/DATASET',\n",
        "\n",
        "    target_size=(224, 224),\n",
        "\n",
        "    color_mode=\"rgb\",\n",
        "\n",
        "    batch_size=32,\n",
        "\n",
        "    class_mode=\"categorical\",\n",
        "\n",
        "    shuffle=True,\n",
        "\n",
        "    seed=42)\n",
        "\n",
        "test_generator= test_datagen.flow_from_directory(\n",
        "\n",
        "   directory='PATH/TO/VALID/DATASET',\n",
        "\n",
        "   target_size=(224,224),color_mode=\"rgb\",\n",
        "\n",
        "   class_mode=\"categorical\",shuffle=False,seed=42)\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce2_1z1gFwTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = SqueezeNet(include_top=False, weights='imagenet',input_tensor=None,input_shape=(224,224,3),pooling=None,classes=1000)\n",
        "\n",
        "x = base_model.output\n",
        "x = Dropout(0.5, name='drop9')(x)\n",
        "x = Convolution2D(256, (1, 1), padding='valid', name='conv10')(x)\n",
        "x = Activation('relu', name='relu_conv10')(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5UuCnTKFzjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1HxpKSZF2VX",
        "colab_type": "code",
        "outputId": "2e3565d1-6da7-4a83-bff3-7983e4986832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 111, 111, 64) 1792        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "relu_conv1 (Activation)         (None, 111, 111, 64) 0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 55, 55, 64)   0           relu_conv1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "fire2/squeeze1x1 (Conv2D)       (None, 55, 55, 16)   1040        pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "fire2/relu_squeeze1x1 (Activati (None, 55, 55, 16)   0           fire2/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire2/expand1x1 (Conv2D)        (None, 55, 55, 64)   1088        fire2/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire2/expand3x3 (Conv2D)        (None, 55, 55, 64)   9280        fire2/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire2/relu_expand1x1 (Activatio (None, 55, 55, 64)   0           fire2/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire2/relu_expand3x3 (Activatio (None, 55, 55, 64)   0           fire2/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire2/concat (Concatenate)      (None, 55, 55, 128)  0           fire2/relu_expand1x1[0][0]       \n",
            "                                                                 fire2/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire3/squeeze1x1 (Conv2D)       (None, 55, 55, 16)   2064        fire2/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire3/relu_squeeze1x1 (Activati (None, 55, 55, 16)   0           fire3/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire3/expand1x1 (Conv2D)        (None, 55, 55, 64)   1088        fire3/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire3/expand3x3 (Conv2D)        (None, 55, 55, 64)   9280        fire3/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire3/relu_expand1x1 (Activatio (None, 55, 55, 64)   0           fire3/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire3/relu_expand3x3 (Activatio (None, 55, 55, 64)   0           fire3/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire3/concat (Concatenate)      (None, 55, 55, 128)  0           fire3/relu_expand1x1[0][0]       \n",
            "                                                                 fire3/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3 (MaxPooling2D)            (None, 27, 27, 128)  0           fire3/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire4/squeeze1x1 (Conv2D)       (None, 27, 27, 32)   4128        pool3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "fire4/relu_squeeze1x1 (Activati (None, 27, 27, 32)   0           fire4/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire4/expand1x1 (Conv2D)        (None, 27, 27, 128)  4224        fire4/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire4/expand3x3 (Conv2D)        (None, 27, 27, 128)  36992       fire4/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire4/relu_expand1x1 (Activatio (None, 27, 27, 128)  0           fire4/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire4/relu_expand3x3 (Activatio (None, 27, 27, 128)  0           fire4/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire4/concat (Concatenate)      (None, 27, 27, 256)  0           fire4/relu_expand1x1[0][0]       \n",
            "                                                                 fire4/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire5/squeeze1x1 (Conv2D)       (None, 27, 27, 32)   8224        fire4/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire5/relu_squeeze1x1 (Activati (None, 27, 27, 32)   0           fire5/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire5/expand1x1 (Conv2D)        (None, 27, 27, 128)  4224        fire5/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire5/expand3x3 (Conv2D)        (None, 27, 27, 128)  36992       fire5/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire5/relu_expand1x1 (Activatio (None, 27, 27, 128)  0           fire5/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire5/relu_expand3x3 (Activatio (None, 27, 27, 128)  0           fire5/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire5/concat (Concatenate)      (None, 27, 27, 256)  0           fire5/relu_expand1x1[0][0]       \n",
            "                                                                 fire5/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool5 (MaxPooling2D)            (None, 13, 13, 256)  0           fire5/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire6/squeeze1x1 (Conv2D)       (None, 13, 13, 48)   12336       pool5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "fire6/relu_squeeze1x1 (Activati (None, 13, 13, 48)   0           fire6/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire6/expand1x1 (Conv2D)        (None, 13, 13, 192)  9408        fire6/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire6/expand3x3 (Conv2D)        (None, 13, 13, 192)  83136       fire6/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire6/relu_expand1x1 (Activatio (None, 13, 13, 192)  0           fire6/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire6/relu_expand3x3 (Activatio (None, 13, 13, 192)  0           fire6/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire6/concat (Concatenate)      (None, 13, 13, 384)  0           fire6/relu_expand1x1[0][0]       \n",
            "                                                                 fire6/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire7/squeeze1x1 (Conv2D)       (None, 13, 13, 48)   18480       fire6/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire7/relu_squeeze1x1 (Activati (None, 13, 13, 48)   0           fire7/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire7/expand1x1 (Conv2D)        (None, 13, 13, 192)  9408        fire7/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire7/expand3x3 (Conv2D)        (None, 13, 13, 192)  83136       fire7/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire7/relu_expand1x1 (Activatio (None, 13, 13, 192)  0           fire7/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire7/relu_expand3x3 (Activatio (None, 13, 13, 192)  0           fire7/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire7/concat (Concatenate)      (None, 13, 13, 384)  0           fire7/relu_expand1x1[0][0]       \n",
            "                                                                 fire7/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire8/squeeze1x1 (Conv2D)       (None, 13, 13, 64)   24640       fire7/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire8/relu_squeeze1x1 (Activati (None, 13, 13, 64)   0           fire8/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire8/expand1x1 (Conv2D)        (None, 13, 13, 256)  16640       fire8/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire8/expand3x3 (Conv2D)        (None, 13, 13, 256)  147712      fire8/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire8/relu_expand1x1 (Activatio (None, 13, 13, 256)  0           fire8/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire8/relu_expand3x3 (Activatio (None, 13, 13, 256)  0           fire8/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire8/concat (Concatenate)      (None, 13, 13, 512)  0           fire8/relu_expand1x1[0][0]       \n",
            "                                                                 fire8/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "fire9/squeeze1x1 (Conv2D)       (None, 13, 13, 64)   32832       fire8/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "fire9/relu_squeeze1x1 (Activati (None, 13, 13, 64)   0           fire9/squeeze1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fire9/expand1x1 (Conv2D)        (None, 13, 13, 256)  16640       fire9/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire9/expand3x3 (Conv2D)        (None, 13, 13, 256)  147712      fire9/relu_squeeze1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fire9/relu_expand1x1 (Activatio (None, 13, 13, 256)  0           fire9/expand1x1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire9/relu_expand3x3 (Activatio (None, 13, 13, 256)  0           fire9/expand3x3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fire9/concat (Concatenate)      (None, 13, 13, 512)  0           fire9/relu_expand1x1[0][0]       \n",
            "                                                                 fire9/relu_expand3x3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "drop9 (Dropout)                 (None, 13, 13, 512)  0           fire9/concat[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv10 (Conv2D)                 (None, 13, 13, 256)  131328      drop9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu_conv10 (Activation)        (None, 13, 13, 256)  0           conv10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 256)          0           relu_conv10[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 7)            1799        global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 855,623\n",
            "Trainable params: 855,623\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMFjkzzYGE4I",
        "colab_type": "code",
        "outputId": "260bb4ef-a889-4d4d-ae63-a559ec7200f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(generator=train_generator,validation_data=valid_generator,validation_steps=STEP_SIZE_VALID,steps_per_epoch=STEP_SIZE_TRAIN,epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0709 12:27:20.277752 140407586551680 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "126/126 [==============================] - 1397s 11s/step - loss: 1.6292 - acc: 0.3425 - val_loss: 0.9762 - val_acc: 0.5411\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 65s 518ms/step - loss: 1.0043 - acc: 0.5429 - val_loss: 0.8969 - val_acc: 0.6253\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 65s 513ms/step - loss: 0.8721 - acc: 0.6099 - val_loss: 0.9630 - val_acc: 0.6085\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 65s 517ms/step - loss: 0.7028 - acc: 0.7110 - val_loss: 0.8910 - val_acc: 0.6764\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 65s 516ms/step - loss: 0.7236 - acc: 0.6997 - val_loss: 0.7335 - val_acc: 0.7150\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 65s 518ms/step - loss: 0.5986 - acc: 0.7716 - val_loss: 0.5888 - val_acc: 0.7863\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 65s 513ms/step - loss: 0.5335 - acc: 0.7956 - val_loss: 0.5733 - val_acc: 0.7829\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 65s 515ms/step - loss: 0.4886 - acc: 0.8179 - val_loss: 0.5863 - val_acc: 0.7703\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 65s 512ms/step - loss: 0.4849 - acc: 0.8108 - val_loss: 0.5064 - val_acc: 0.7988\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 65s 519ms/step - loss: 0.5499 - acc: 0.7879 - val_loss: 0.5008 - val_acc: 0.8039\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 66s 520ms/step - loss: 0.4239 - acc: 0.8276 - val_loss: 0.5466 - val_acc: 0.7913\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 65s 514ms/step - loss: 0.4001 - acc: 0.8408 - val_loss: 0.4625 - val_acc: 0.8131\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 64s 508ms/step - loss: 0.3493 - acc: 0.8631 - val_loss: 0.4864 - val_acc: 0.8273\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 65s 514ms/step - loss: 0.3988 - acc: 0.8487 - val_loss: 0.6161 - val_acc: 0.7804\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 66s 523ms/step - loss: 0.3747 - acc: 0.8493 - val_loss: 0.4303 - val_acc: 0.8290\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 66s 522ms/step - loss: 0.3878 - acc: 0.8497 - val_loss: 0.3837 - val_acc: 0.8458\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 65s 516ms/step - loss: 0.3650 - acc: 0.8653 - val_loss: 0.4686 - val_acc: 0.8407\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 64s 511ms/step - loss: 0.3551 - acc: 0.8616 - val_loss: 0.4761 - val_acc: 0.8340\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 66s 525ms/step - loss: 0.3179 - acc: 0.8755 - val_loss: 0.4237 - val_acc: 0.8508\n",
            "Epoch 20/100\n",
            "126/126 [==============================] - 64s 505ms/step - loss: 0.2851 - acc: 0.9000 - val_loss: 0.4279 - val_acc: 0.8441\n",
            "Epoch 21/100\n",
            "126/126 [==============================] - 66s 523ms/step - loss: 0.3173 - acc: 0.8859 - val_loss: 0.4114 - val_acc: 0.8357\n",
            "Epoch 22/100\n",
            "126/126 [==============================] - 64s 506ms/step - loss: 0.3078 - acc: 0.8814 - val_loss: 0.5787 - val_acc: 0.8156\n",
            "Epoch 23/100\n",
            "126/126 [==============================] - 65s 515ms/step - loss: 0.5562 - acc: 0.7865 - val_loss: 0.4395 - val_acc: 0.8365\n",
            "Epoch 24/100\n",
            "126/126 [==============================] - 65s 516ms/step - loss: 0.2923 - acc: 0.8891 - val_loss: 0.4342 - val_acc: 0.8399\n",
            "Epoch 25/100\n",
            "126/126 [==============================] - 66s 522ms/step - loss: 0.2904 - acc: 0.8941 - val_loss: 0.4755 - val_acc: 0.8265\n",
            "Epoch 26/100\n",
            "126/126 [==============================] - 65s 513ms/step - loss: 0.4850 - acc: 0.8251 - val_loss: 0.5002 - val_acc: 0.8365\n",
            "Epoch 27/100\n",
            "126/126 [==============================] - 64s 511ms/step - loss: 0.5733 - acc: 0.7949 - val_loss: 0.5047 - val_acc: 0.8080\n",
            "Epoch 28/100\n",
            "126/126 [==============================] - 65s 517ms/step - loss: 0.3367 - acc: 0.8725 - val_loss: 0.4175 - val_acc: 0.8483\n",
            "Epoch 29/100\n",
            "126/126 [==============================] - 65s 520ms/step - loss: 0.2429 - acc: 0.9134 - val_loss: 0.4802 - val_acc: 0.8541\n",
            "Epoch 30/100\n",
            "126/126 [==============================] - 65s 515ms/step - loss: 0.2506 - acc: 0.9167 - val_loss: 0.5169 - val_acc: 0.8483\n",
            "Epoch 31/100\n",
            "126/126 [==============================] - 64s 508ms/step - loss: 0.5201 - acc: 0.8004 - val_loss: 0.4753 - val_acc: 0.7829\n",
            "Epoch 32/100\n",
            "126/126 [==============================] - 65s 519ms/step - loss: 0.2956 - acc: 0.8829 - val_loss: 0.4443 - val_acc: 0.8332\n",
            "Epoch 33/100\n",
            "126/126 [==============================] - 64s 506ms/step - loss: 0.3251 - acc: 0.8869 - val_loss: 0.4372 - val_acc: 0.8676\n",
            "Epoch 34/100\n",
            "126/126 [==============================] - 65s 519ms/step - loss: 0.2078 - acc: 0.9162 - val_loss: 0.4595 - val_acc: 0.8533\n",
            "Epoch 35/100\n",
            "126/126 [==============================] - 65s 518ms/step - loss: 0.1787 - acc: 0.9363 - val_loss: 0.4090 - val_acc: 0.8692\n",
            "Epoch 36/100\n",
            "126/126 [==============================] - 64s 507ms/step - loss: 0.1520 - acc: 0.9447 - val_loss: 0.4679 - val_acc: 0.8751\n",
            "Epoch 37/100\n",
            "126/126 [==============================] - 65s 514ms/step - loss: 0.2222 - acc: 0.9209 - val_loss: 0.4666 - val_acc: 0.8474\n",
            "Epoch 38/100\n",
            "126/126 [==============================] - 64s 509ms/step - loss: 0.1436 - acc: 0.9479 - val_loss: 0.4808 - val_acc: 0.8642\n",
            "Epoch 39/100\n",
            "126/126 [==============================] - 65s 518ms/step - loss: 0.1319 - acc: 0.9554 - val_loss: 0.5634 - val_acc: 0.8382\n",
            "Epoch 40/100\n",
            "126/126 [==============================] - 64s 511ms/step - loss: 0.1528 - acc: 0.9422 - val_loss: 0.4906 - val_acc: 0.8816\n",
            "Epoch 41/100\n",
            "126/126 [==============================] - 66s 523ms/step - loss: 0.1709 - acc: 0.9425 - val_loss: 0.4656 - val_acc: 0.8718\n",
            "Epoch 42/100\n",
            "126/126 [==============================] - 66s 525ms/step - loss: 0.1818 - acc: 0.9400 - val_loss: 0.5493 - val_acc: 0.8583\n",
            "Epoch 43/100\n",
            "126/126 [==============================] - 64s 510ms/step - loss: 0.1312 - acc: 0.9541 - val_loss: 0.4819 - val_acc: 0.8885\n",
            "Epoch 44/100\n",
            "126/126 [==============================] - 67s 532ms/step - loss: 0.1287 - acc: 0.9551 - val_loss: 0.5007 - val_acc: 0.8759\n",
            "Epoch 45/100\n",
            "126/126 [==============================] - 64s 505ms/step - loss: 0.1199 - acc: 0.9588 - val_loss: 0.6333 - val_acc: 0.8634\n",
            "Epoch 46/100\n",
            "126/126 [==============================] - 66s 524ms/step - loss: 0.1601 - acc: 0.9496 - val_loss: 0.5736 - val_acc: 0.8315\n",
            "Epoch 47/100\n",
            "126/126 [==============================] - 65s 512ms/step - loss: 0.1757 - acc: 0.9392 - val_loss: 0.7616 - val_acc: 0.7972\n",
            "Epoch 48/100\n",
            "126/126 [==============================] - 68s 542ms/step - loss: 0.1400 - acc: 0.9521 - val_loss: 0.4953 - val_acc: 0.8801\n",
            "Epoch 49/100\n",
            "126/126 [==============================] - 65s 517ms/step - loss: 0.1261 - acc: 0.9573 - val_loss: 0.4987 - val_acc: 0.8868\n",
            "Epoch 50/100\n",
            "126/126 [==============================] - 66s 525ms/step - loss: 0.0826 - acc: 0.9732 - val_loss: 0.5670 - val_acc: 0.8894\n",
            "Epoch 51/100\n",
            "126/126 [==============================] - 64s 506ms/step - loss: 0.1211 - acc: 0.9650 - val_loss: 0.5833 - val_acc: 0.8684\n",
            "Epoch 52/100\n",
            "126/126 [==============================] - 65s 518ms/step - loss: 0.1598 - acc: 0.9526 - val_loss: 0.4436 - val_acc: 0.8927\n",
            "Epoch 53/100\n",
            "126/126 [==============================] - 63s 503ms/step - loss: 0.1469 - acc: 0.9516 - val_loss: 0.5387 - val_acc: 0.8634\n",
            "Epoch 54/100\n",
            "126/126 [==============================] - 66s 522ms/step - loss: 0.1446 - acc: 0.9546 - val_loss: 0.7700 - val_acc: 0.8676\n",
            "Epoch 55/100\n",
            "126/126 [==============================] - 65s 518ms/step - loss: 0.1741 - acc: 0.9549 - val_loss: 1.1308 - val_acc: 0.6882\n",
            "Epoch 56/100\n",
            "126/126 [==============================] - 65s 516ms/step - loss: 0.2721 - acc: 0.9070 - val_loss: 0.4814 - val_acc: 0.8567\n",
            "Epoch 57/100\n",
            "126/126 [==============================] - 65s 512ms/step - loss: 0.1152 - acc: 0.9583 - val_loss: 0.4234 - val_acc: 0.9028\n",
            "Epoch 58/100\n",
            "126/126 [==============================] - 66s 524ms/step - loss: 0.0725 - acc: 0.9792 - val_loss: 0.4727 - val_acc: 0.8910\n",
            "Epoch 59/100\n",
            "126/126 [==============================] - 65s 519ms/step - loss: 0.1390 - acc: 0.9581 - val_loss: 0.5445 - val_acc: 0.8894\n",
            "Epoch 60/100\n",
            "126/126 [==============================] - 63s 498ms/step - loss: 0.0893 - acc: 0.9730 - val_loss: 0.4665 - val_acc: 0.8910\n",
            "Epoch 61/100\n",
            "126/126 [==============================] - 65s 519ms/step - loss: 0.7497 - acc: 0.7173 - val_loss: 0.9392 - val_acc: 0.5608\n",
            "Epoch 62/100\n",
            "126/126 [==============================] - 66s 522ms/step - loss: 0.7964 - acc: 0.6409 - val_loss: 0.7259 - val_acc: 0.6882\n",
            "Epoch 63/100\n",
            "126/126 [==============================] - 66s 526ms/step - loss: 0.6671 - acc: 0.7046 - val_loss: 0.7822 - val_acc: 0.6580\n",
            "Epoch 64/100\n",
            "126/126 [==============================] - 63s 500ms/step - loss: 0.5972 - acc: 0.7482 - val_loss: 0.6099 - val_acc: 0.7930\n",
            "Epoch 65/100\n",
            "126/126 [==============================] - 67s 530ms/step - loss: 0.5403 - acc: 0.7812 - val_loss: 0.6447 - val_acc: 0.6991\n",
            "Epoch 66/100\n",
            "126/126 [==============================] - 63s 499ms/step - loss: 0.4494 - acc: 0.8256 - val_loss: 0.5385 - val_acc: 0.7904\n",
            "Epoch 67/100\n",
            "126/126 [==============================] - 66s 527ms/step - loss: 0.4111 - acc: 0.8338 - val_loss: 0.4711 - val_acc: 0.8416\n",
            "Epoch 68/100\n",
            "126/126 [==============================] - 65s 513ms/step - loss: 0.4110 - acc: 0.8341 - val_loss: 0.5758 - val_acc: 0.8039\n",
            "Epoch 69/100\n",
            "126/126 [==============================] - 64s 512ms/step - loss: 0.4195 - acc: 0.8274 - val_loss: 0.4463 - val_acc: 0.8458\n",
            "Epoch 70/100\n",
            " 40/126 [========>.....................] - ETA: 33s - loss: 0.3834 - acc: 0.8656"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8cK-VOKLsL4",
        "colab_type": "code",
        "outputId": "c384a65c-fbd0-471d-cc67-194d1955fafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#EVALUATE the model\n",
        "model.evaluate_generator(test_generator,steps = STEP_SIZE_TEST, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13583221323654016, 0.96875]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhDYloY5JqAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving the model\n",
        "model.save(\"PATH/TO/SAVE/MODEL/SqueezeNets.model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S55olc3j4X0",
        "colab_type": "text"
      },
      "source": [
        "##Converting to TfLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcs1BIkIKJpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "converter  = tf.lite.TFLiteConverter.from_keras_model_file(\"PATH/TO/SAVED/MODEL/SqueezeNets.model\", input_shapes = {'input_1' : [1,224,224,3]})\n",
        "tflite_model  = converter.convert()\n",
        "\n",
        "open(\"PATH/TO/SAVE/MODEL/SqueezeNetS.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBUv149fkBTw",
        "colab_type": "text"
      },
      "source": [
        "##Getting the F1 scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbUOlwRDcjuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "validation_data_dir = \"PATH/TO/DATASET\"\n",
        "import glob\n",
        "allvalidimgpaths=glob.glob(os.path.join(validation_data_dir, '*/*.jpeg'))\n",
        "allvalidimgpaths+=glob.glob(os.path.join(validation_data_dir, '*/*.jpg'))\n",
        "import random\n",
        "random.shuffle(allvalidimgpaths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrPgLp-2d-DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "validation_imgs = [img_to_array(load_img(img, target_size=(224,224))) for img in allvalidimgpaths]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooCBizCQeHOV",
        "colab_type": "code",
        "outputId": "691247e9-a906-424d-b19d-6c51a68d13c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_labels= [fn.split('/')[-2] for fn in allvalidimgpaths]\n",
        "\n",
        "import numpy as np\n",
        "np.array(validation_imgs)\n",
        "\n",
        "print(np.shape(validation_imgs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(221, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1CTq66geKZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "#LABELS\n",
        "le.fit([\"black eyed beans\",\"chana dal\",\"kidney beans\",\"masoor dal\",\"moong dal\",\"toor dal\",\"urad dal\"])\n",
        "validation_labels_enc = le.transform(validation_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yntfA2haePx1",
        "colab_type": "code",
        "outputId": "58240e92-6ebc-4d65-ee7a-6bb98bd6ef10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(validation_labels[5:9])\n",
        "print(validation_labels_enc[5:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['chana dal', 'masoor dal', 'kidney beans', 'toor dal']\n",
            "[1 3 2 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDemlrNde6ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"PATH/TO/SAVED/MODEL/SqueezeNets.model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erezfjvDevlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "newvalids=validation_imgs[:]\n",
        "\n",
        "valid_imgs_array=numpy.asarray(validation_imgs)\n",
        "\n",
        "print(valid_imgs_array.shape)\n",
        "valid_imgs_array.astype('float32')\n",
        "\n",
        "#valid_imgs_array/=255\n",
        "\n",
        "test_predictions=model.predict(valid_imgs_array)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03qpzT5SfYMg",
        "colab_type": "code",
        "outputId": "0057f6f7-8300-440b-958d-2c50c0d78bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "import numpy as np\n",
        "newpreds= np.argmax(test_predictions,axis=1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(validation_labels_enc, newpreds, target_names=[\"black eyed beans\",\"chana dal\",\"kidney beans\",\"masoor dal\",\"moong dal\",\"toor dal\",\"urad dal\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "black eyed beans       0.97      1.00      0.99        34\n",
            "       chana dal       0.69      0.85      0.76        13\n",
            "    kidney beans       1.00      0.96      0.98        75\n",
            "      masoor dal       1.00      0.99      0.99        70\n",
            "       moong dal       0.67      1.00      0.80         4\n",
            "        toor dal       1.00      0.88      0.93        16\n",
            "        urad dal       0.89      0.89      0.89         9\n",
            "\n",
            "        accuracy                           0.96       221\n",
            "       macro avg       0.89      0.94      0.91       221\n",
            "    weighted avg       0.97      0.96      0.96       221\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}